{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "825799df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import openai\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c1481c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "768b17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f5eb4b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('', [('안녕하세요', '감사합니다.')])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [] # 리스트 초기화 - 대화 내용 기록.\n",
    "def respond_test(prompt, chat_history):\n",
    "  print(chat_history)\n",
    "  chat_history.append((prompt, \"감사합니다.\")) # (user 질문, assistant 답변)\n",
    "  return \"\", chat_history\n",
    "# 튜플 리턴(UI 와 연동하는 리턴)\n",
    "# ↪ 첫번째 요소 \"\" : 요청 보낸 후에 요청 입력 상자는 clear\n",
    "# ↪ 두번째 요소 chat_history : (user 질문, assistant 답변) 튜플을 저장하는 리스트\n",
    "# 테스트                          질문과 답변을 기록 출력 요소에 전달.\n",
    "respond_test(\"안녕하세요\", chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba332fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('안녕하세요', '감사합니다.')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('', [('안녕하세요', '감사합니다.'), ('안녕히 가세요', '감사합니다.')])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond_test(\"안녕히 가세요\", chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb193b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4.1-mini\"\n",
    "def respond(prompt,chat_history): # ui 와 연결할 함수\n",
    "  instruction = \"\"\"\n",
    "  는 피자 가격을 안내하는 챗봇이다.\n",
    "    주요 임무는 다음과 같다:\n",
    "    1. 현재는 가격 정보만 제공하는 임무를 맞고 있으니 그 외의 다른 정보는 제공할 수 없음.\n",
    "    2. 피자의 종류에 대한 가격 안내만 할 수 있음.\n",
    "    2. 불필요한 잡담은 최소화하고, 주문과 관련된 대화에 집중한다.\n",
    "    3. 항상 정중하고 친근한 말투를 유지한다.\n",
    "    인사말과 피자 주문 이외의 다른 요청은 '챗봇 기능과 다른 질문입니다.' 라고 답변해.\n",
    "    \"\"\"\n",
    "  # 너는 피자 주문을 돕는 챗봇이다.\n",
    "  # 친절하고 간단명료하게 대화하며, 고객이 원하는 피자를 정확히 주문할 수 있도록 안내한다.\n",
    "  # 1. 고객의 주문 의도를 파악한다 (피자 종류, 사이즈, 토핑, 수량, 음료, 사이드 메뉴 등).\n",
    "  # 2. 필요한 경우 추가 질문을 하여 주문 정보를 완성한다.\n",
    "  # 3. 주문 내용을 고객에게 다시 확인시켜준다.\n",
    "  # 4. 결제나 배달 관련 정보는 기본적인 안내만 하고, 실제 결제는 외부 시스템에서 처리된다고 설명한다.\n",
    "  messages = [{\"role\" : \"system\", \"content\" : instruction}, {\"role\" : \"user\", \"content\": prompt}]\n",
    "\n",
    "  res = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages = messages\n",
    "  )\n",
    "  answer = res.choices[0].message.content\n",
    "  # 여기까지가 GPT 와 통신하고 응답받는 코드\n",
    "\n",
    "  chat_history.append((prompt, answer))\n",
    "  print(chat_history)\n",
    "  return \"\", chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aa9b6164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('하이', '챗봇 기능과 다른 질문입니다.')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('', [('하이', '챗봇 기능과 다른 질문입니다.')])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history=[]\n",
    "result = respond('하이', chat_history)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8d5bf14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('하이', '챗봇 기능과 다른 질문입니다.'), ('대한민국의 수도는 어디야?', '챗봇 기능과 다른 질문입니다.')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('', [('하이', '챗봇 기능과 다른 질문입니다.'), ('대한민국의 수도는 어디야?', '챗봇 기능과 다른 질문입니다.')])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = respond('대한민국의 수도는 어디야?', chat_history)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1bf54e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\C118\\AppData\\Local\\Temp\\ipykernel_6840\\3812739030.py:10: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Chat_History\") # 대화 기록을 보여주는 컴포넌트\n"
     ]
    }
   ],
   "source": [
    "chat_history=[]\n",
    "with gr.Blocks() as app:\n",
    "  gr.Markdown(\"# 챗봇\")\n",
    "  gr.Markdown(\n",
    "    \"\"\"\n",
    "    ## Chat\n",
    "    얻고 싶은 정보에 대해 질문해보세요.\n",
    "    \"\"\"\n",
    "  )\n",
    "  chatbot = gr.Chatbot(label=\"Chat_History\") # 대화 기록을 보여주는 컴포넌트\n",
    "  prompt = gr.Textbox(label=\"input prompt\", interactive=True)\n",
    "  clear = gr.ClearButton([prompt, chatbot])\n",
    "  # 텍스트박스에서 엔터 -> submit. gpt api 요청 보내기\n",
    "  prompt.submit(respond, [prompt, chatbot], [prompt, chatbot])\n",
    "  #                       함수,            함수의 입력,           함수의 리턴 (\"\", caht_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36cd3d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('포테이토피자 가격 알려줘', '포테이토피자의 가격은 15,000원입니다. 다른 피자 가격도 필요하시면 말씀해 주세요!')]\n"
     ]
    }
   ],
   "source": [
    "app.launch(inline=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6f457c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2592001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
